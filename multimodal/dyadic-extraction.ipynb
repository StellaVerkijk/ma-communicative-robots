{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bitdevpython378e162af75d134820b03d49898b79756f",
   "display_name": "Python 3.7.9 64-bit ('dev-python-3.7')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "there are 9989 vids in train dataset\n",
      "there are 1112 vids in dev dataset\n",
      "there are 2747 vids in test dataset\n",
      "\n",
      "there are 99 utterances in dyadic train set\n",
      "there are 20 dialogues in dyadic train set\n",
      "\n",
      "there are 81 utterances in dyadic dev set\n",
      "there are 15 dialogues in dyadic dev set\n",
      "\n",
      "there are 78 utterances in dyadic test set\n",
      "there are 19 dialogues in dyadic test set\n",
      "\n"
     ]
    }
   ],
   "source": [
    "annotation_path = {'train': '/home/tk/repos/MELD/data/MELD_Dyadic/train_sent_emo_dya.csv',\n",
    "                        'dev': '/home/tk/repos/MELD/data/MELD_Dyadic/dev_sent_emo_dya.csv',\n",
    "                        'test': '/home/tk/repos/MELD/data/MELD_Dyadic/train_sent_emo_dya.csv'}\n",
    "\n",
    "vid_path = {'train': \"/home/tk/datasets/MELD/MELD.Raw/train/train_splits\",\n",
    "                'dev': \"/home/tk/datasets/MELD/MELD.Raw/dev/dev_splits_complete\",\n",
    "                'test': \"/home/tk/datasets/MELD/MELD.Raw/test/output_repeated_splits_test\"}\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import csv\n",
    "\n",
    "annotations = {}\n",
    "for key, val in annotation_path.items():\n",
    "    with open(val) as f:\n",
    "        reader = csv.reader(f)\n",
    "        annotations[key] = list(reader)\n",
    "\n",
    "vids = {}\n",
    "for key, val in vid_path.items():\n",
    "    vids[key] = glob(os.path.join(val, '*.mp4'))\n",
    "    vids[key] = [os.path.basename(vid) for vid in vids[key]]\n",
    "    print(f\"there are {len(vids[key])} vids in {key} dataset\")\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "vids_dyadic = {}\n",
    "for dataset, long_list in annotations.items():\n",
    "    vids_dyadic[dataset] = []\n",
    "    for row in long_list:\n",
    "        name = row[2]\n",
    "        did = row[5]\n",
    "        uid = row[6]\n",
    "        vidfile = f\"dia{did}_utt{uid}.mp4\"\n",
    "        if vidfile in vids[dataset]:\n",
    "            vids_dyadic[dataset].append(vidfile)\n",
    "    vids_dyadic[dataset] = sorted(list(set(vids_dyadic[dataset])))\n",
    "    print(f\"there are {len(vids_dyadic[dataset])} utterances in dyadic {dataset} set\")\n",
    "    print(f\"there are {len(set([foo.split('_')[0] for foo in vids_dyadic[dataset]]))} dialogues in dyadic {dataset} set\")\n",
    "    print()\n",
    "\n",
    "import json\n",
    "\n",
    "with open('./vids-dyadic.json', 'w') as stream:\n",
    "    json.dump(vids_dyadic, stream)"
   ]
  }
 ]
}