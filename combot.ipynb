{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "from representation.container import TemporalContainer, Ruler, TemporalRuler\n",
    "from representation.entity import Friend, Person, Object, Gender, Emotion\n",
    "from representation.util import Identifier, serializer\n",
    "from representation.entity import Friend, Gender, Emotion\n",
    "from representation.scenario import Scenario, ScenarioContext, Modality, Mention\n",
    "from representation.scenario import ImageSignal, TextSignal, append_signal\n",
    "from representation.mention import UtteranceAnnotation, PersonAnnotation, Token, Triple\n",
    "from representation.util import serializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a time segments for the signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenario_data_path(scenario_id, file_name, modality=None, data_dir=\"data/test-scenes\"):\n",
    "    path = os.path.join(data_dir, str(scenario_id))\n",
    "    if modality:\n",
    "        path = os.path.join(path, modality.name.lower())\n",
    "    \n",
    "    return os.path.join(path, file_name)\n",
    "\n",
    "def clean(scenario_id, data_dir=\"data/test-scenes\"):\n",
    "    # clean data\n",
    "    path = scenario_data_path(scenario_id, \"\", data_dir=data_dir)\n",
    "    json_files = (os.path.join(root, file)\n",
    "             for root, _, files in os.walk(path)\n",
    "             for file in files if file.endswith(\".json\"))\n",
    "\n",
    "    for file in json_files:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "            print(\"Cleaned\", file)\n",
    "        except OSError:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data/test-scenes/test_scenario/test_scenario.json\n",
      "Cleaned data/test-scenes/test_scenario/image.json\n",
      "Cleaned data/test-scenes/test_scenario/text.json\n",
      "{\n",
      "    \"start_time\": 1603139000,\n",
      "    \"end_time\": 1603150000,\n",
      "    \"id\": \"test_scenario\",\n",
      "    \"ruler\": {\n",
      "        \"type\": \"TemporalRuler\",\n",
      "        \"container_id\": \"test_scenario\",\n",
      "        \"start\": 1603139000,\n",
      "        \"end\": 1603150000\n",
      "    },\n",
      "    \"context\": {\n",
      "        \"agent\": \"leolani\",\n",
      "        \"speaker\": {\n",
      "            \"id\": \"902ddf2c-64b1-4cd0-8fed-e7690f1b8e05\",\n",
      "            \"name\": \"Piek\",\n",
      "            \"age\": 59,\n",
      "            \"gender\": \"MALE\",\n",
      "            \"emotion\": null\n",
      "        },\n",
      "        \"persons\": [],\n",
      "        \"objects\": []\n",
      "    },\n",
      "    \"signals\": {\n",
      "        \"image\": \"data/test-scenes/test_scenario/image.json\",\n",
      "        \"text\": \"data/test-scenes/test_scenario/text.json\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "scenario_id = \"test_scenario\"\n",
    "clean(scenario_id)\n",
    "\n",
    "piek = Friend(None, \"Piek\", 59, Gender.MALE, None)\n",
    "context = ScenarioContext(\"leolani\", piek, [], [])\n",
    "signals = {\n",
    "    Modality.IMAGE.name.lower(): scenario_data_path(scenario_id, Modality.IMAGE.name.lower() + \".json\"),\n",
    "    Modality.TEXT.name.lower(): scenario_data_path(scenario_id, Modality.TEXT.name.lower() + \".json\")\n",
    "}\n",
    "scenario = Scenario(scenario_id, 1603139000, 1603150000, context, signals)\n",
    "\n",
    "print(json.dumps(scenario, default=serializer, indent=4))\n",
    "\n",
    "scenario_path = scenario_data_path(scenario_id, str(scenario_id) + \".json\")\n",
    "os.makedirs(os.path.dirname(scenario_path), exist_ok=True)\n",
    "with open(scenario_path, 'w') as scenario_file:\n",
    "    json.dump(scenario, scenario_file, default=serializer, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the speaker and his/her emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"modality\": \"IMAGE\",\n",
      "    \"time\": {\n",
      "        \"type\": \"TemporalRuler\",\n",
      "        \"container_id\": \"test_scenario\",\n",
      "        \"start\": 1603139705,\n",
      "        \"end\": 1603140000\n",
      "    },\n",
      "    \"files\": [\n",
      "        \"data/test-scenes/test_scenario/image/piek-1.jpg\"\n",
      "    ],\n",
      "    \"mentions\": [\n",
      "        {\n",
      "            \"type\": \"PersonAnnotation\",\n",
      "            \"segment\": {\n",
      "                \"type\": \"MultiIndex\",\n",
      "                \"container_id\": \"66fafca3-2c14-4b69-84b7-5fdaa06ffe0a\",\n",
      "                \"bounds\": [\n",
      "                    [\n",
      "                        10,\n",
      "                        521\n",
      "                    ],\n",
      "                    [\n",
      "                        15,\n",
      "                        518\n",
      "                    ]\n",
      "                ]\n",
      "            },\n",
      "            \"source\": \"face_recognitions\",\n",
      "            \"timestamp\": 1604697979.097769,\n",
      "            \"person\": {\n",
      "                \"id\": \"7cdd5e66-1143-418a-95d8-bcc0fa837af2\",\n",
      "                \"name\": \"Piek\",\n",
      "                \"age\": 59,\n",
      "                \"gender\": \"MALE\",\n",
      "                \"emotion\": \"JOY\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"array\": null,\n",
      "    \"id\": \"66fafca3-2c14-4b69-84b7-5fdaa06ffe0a\",\n",
      "    \"ruler\": {\n",
      "        \"type\": \"MultiIndex\",\n",
      "        \"container_id\": \"66fafca3-2c14-4b69-84b7-5fdaa06ffe0a\",\n",
      "        \"bounds\": [\n",
      "            [\n",
      "                0,\n",
      "                550\n",
      "            ],\n",
      "            [\n",
      "                0,\n",
      "                550\n",
      "            ]\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "speaker_img_file = scenario_data_path(scenario_id, \"piek-1.jpg\", Modality.IMAGE)\n",
    "speaker_img_time = scenario.ruler.get_time_segment(1603139705, 1603140000)\n",
    "\n",
    "speaker_img_signal = ImageSignal(None, speaker_img_time, [speaker_img_file], ((0, 550), (0, 550)))\n",
    "speaker_bounding_box = speaker_img_signal.ruler.get_area_bounding_box(10,15,521,518)\n",
    "piek = Friend(None, \"Piek\", 59, Gender.MALE, Emotion.JOY)\n",
    "speaker = PersonAnnotation(piek, speaker_bounding_box, \"face_recognition\", time.time())\n",
    "speaker_img_signal.mentions.append(speaker)\n",
    "\n",
    "\n",
    "print(json.dumps(speaker_img_signal, default=serializer, indent=4))\n",
    "append_signal(scenario.signals[Modality.IMAGE.name.lower()], speaker_img_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, ((0, 4), 'That')),\n",
      " (1, ((5, 7), 'is')),\n",
      " (2, ((8, 10), 'my')),\n",
      " (3, ((11, 18), 'brother')),\n",
      " (4, ((19, 22), 'Jim'))]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    offsets = tuple(TreebankWordTokenizer().span_tokenize(text))\n",
    "    \n",
    "    return tuple(((start, end), text[start:end]) for start, end in offsets)\n",
    "    \n",
    "pprint([t for t in enumerate(tokenize(\"That is my brother Jim\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"modality\": \"TEXT\",\n",
      "    \"time\": {\n",
      "        \"type\": \"TemporalRuler\",\n",
      "        \"container_id\": \"test_scenario\",\n",
      "        \"start\": 1603139850,\n",
      "        \"end\": 1603149890\n",
      "    },\n",
      "    \"files\": [\n",
      "        \"data/test-scenes/test_scenario/text/chat1_utterance1.txt\"\n",
      "    ],\n",
      "    \"mentions\": [\n",
      "        {\n",
      "            \"type\": \"Token\",\n",
      "            \"segment\": {\n",
      "                \"type\": \"Index\",\n",
      "                \"container_id\": \"9b3b792c-797c-44a2-a340-9f64cd532c67\",\n",
      "                \"start\": 0,\n",
      "                \"stop\": 4\n",
      "            },\n",
      "            \"source\": \"treebank_tokenizer\",\n",
      "            \"timestamp\": 1604697979.1308181,\n",
      "            \"value\": \"That\",\n",
      "            \"id\": \"0ee3d4f0-de33-4074-961f-4c8719e56012\",\n",
      "            \"ruler\": {\n",
      "                \"type\": \"AtomicRuler\",\n",
      "                \"container_id\": \"0ee3d4f0-de33-4074-961f-4c8719e56012\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"Token\",\n",
      "            \"segment\": {\n",
      "                \"type\": \"Index\",\n",
      "                \"container_id\": \"9b3b792c-797c-44a2-a340-9f64cd532c67\",\n",
      "                \"start\": 5,\n",
      "                \"stop\": 7\n",
      "            },\n",
      "            \"source\": \"treebank_tokenizer\",\n",
      "            \"timestamp\": 1604697979.131271,\n",
      "            \"value\": \"is\",\n",
      "            \"id\": \"2c2d6603-b329-4254-b68c-2fc135ee819e\",\n",
      "            \"ruler\": {\n",
      "                \"type\": \"AtomicRuler\",\n",
      "                \"container_id\": \"2c2d6603-b329-4254-b68c-2fc135ee819e\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"Token\",\n",
      "            \"segment\": {\n",
      "                \"type\": \"Index\",\n",
      "                \"container_id\": \"9b3b792c-797c-44a2-a340-9f64cd532c67\",\n",
      "                \"start\": 8,\n",
      "                \"stop\": 10\n",
      "            },\n",
      "            \"source\": \"treebank_tokenizer\",\n",
      "            \"timestamp\": 1604697979.13138,\n",
      "            \"value\": \"my\",\n",
      "            \"id\": \"a7d1eedd-b87f-4315-969d-024f80228895\",\n",
      "            \"ruler\": {\n",
      "                \"type\": \"AtomicRuler\",\n",
      "                \"container_id\": \"a7d1eedd-b87f-4315-969d-024f80228895\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"Token\",\n",
      "            \"segment\": {\n",
      "                \"type\": \"Index\",\n",
      "                \"container_id\": \"9b3b792c-797c-44a2-a340-9f64cd532c67\",\n",
      "                \"start\": 11,\n",
      "                \"stop\": 18\n",
      "            },\n",
      "            \"source\": \"treebank_tokenizer\",\n",
      "            \"timestamp\": 1604697979.1314108,\n",
      "            \"value\": \"brother\",\n",
      "            \"id\": \"e08897df-91e2-43e6-9f79-3112d930cb9a\",\n",
      "            \"ruler\": {\n",
      "                \"type\": \"AtomicRuler\",\n",
      "                \"container_id\": \"e08897df-91e2-43e6-9f79-3112d930cb9a\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"Token\",\n",
      "            \"segment\": {\n",
      "                \"type\": \"Index\",\n",
      "                \"container_id\": \"9b3b792c-797c-44a2-a340-9f64cd532c67\",\n",
      "                \"start\": 19,\n",
      "                \"stop\": 22\n",
      "            },\n",
      "            \"source\": \"treebank_tokenizer\",\n",
      "            \"timestamp\": 1604697979.1314318,\n",
      "            \"value\": \"Jim\",\n",
      "            \"id\": \"b4c4381f-73e7-4573-a3c2-ed7730020e0a\",\n",
      "            \"ruler\": {\n",
      "                \"type\": \"AtomicRuler\",\n",
      "                \"container_id\": \"b4c4381f-73e7-4573-a3c2-ed7730020e0a\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"chat_id\": \"2fc422bd-c075-4983-9b17-f2c2eb3f0c4a\",\n",
      "            \"utterance\": \"That is my brother Jim\\n\",\n",
      "            \"emotion\": \"JOY\",\n",
      "            \"type\": \"UtteranceAnnotation\",\n",
      "            \"segment\": [\n",
      "                {\n",
      "                    \"type\": \"AtomicRuler\",\n",
      "                    \"container_id\": \"0ee3d4f0-de33-4074-961f-4c8719e56012\"\n",
      "                },\n",
      "                {\n",
      "                    \"type\": \"AtomicRuler\",\n",
      "                    \"container_id\": \"2c2d6603-b329-4254-b68c-2fc135ee819e\"\n",
      "                },\n",
      "                {\n",
      "                    \"type\": \"AtomicRuler\",\n",
      "                    \"container_id\": \"a7d1eedd-b87f-4315-969d-024f80228895\"\n",
      "                },\n",
      "                {\n",
      "                    \"type\": \"AtomicRuler\",\n",
      "                    \"container_id\": \"e08897df-91e2-43e6-9f79-3112d930cb9a\"\n",
      "                },\n",
      "                {\n",
      "                    \"type\": \"AtomicRuler\",\n",
      "                    \"container_id\": \"b4c4381f-73e7-4573-a3c2-ed7730020e0a\"\n",
      "                }\n",
      "            ],\n",
      "            \"source\": \"annotator_1\",\n",
      "            \"timestamp\": 1604697979.131764,\n",
      "            \"seq\": [\n",
      "                {\n",
      "                    \"type\": \"Token\",\n",
      "                    \"segment\": {\n",
      "                        \"type\": \"Index\",\n",
      "                        \"container_id\": \"9b3b792c-797c-44a2-a340-9f64cd532c67\",\n",
      "                        \"start\": 0,\n",
      "                        \"stop\": 4\n",
      "                    },\n",
      "                    \"source\": \"treebank_tokenizer\",\n",
      "                    \"timestamp\": 1604697979.1308181,\n",
      "                    \"value\": \"That\",\n",
      "                    \"id\": \"0ee3d4f0-de33-4074-961f-4c8719e56012\",\n",
      "                    \"ruler\": {\n",
      "                        \"type\": \"AtomicRuler\",\n",
      "                        \"container_id\": \"0ee3d4f0-de33-4074-961f-4c8719e56012\"\n",
      "                    }\n",
      "                },\n",
      "                {\n",
      "                    \"type\": \"Token\",\n",
      "                    \"segment\": {\n",
      "                        \"type\": \"Index\",\n",
      "                        \"container_id\": \"9b3b792c-797c-44a2-a340-9f64cd532c67\",\n",
      "                        \"start\": 5,\n",
      "                        \"stop\": 7\n",
      "                    },\n",
      "                    \"source\": \"treebank_tokenizer\",\n",
      "                    \"timestamp\": 1604697979.131271,\n",
      "                    \"value\": \"is\",\n",
      "                    \"id\": \"2c2d6603-b329-4254-b68c-2fc135ee819e\",\n",
      "                    \"ruler\": {\n",
      "                        \"type\": \"AtomicRuler\",\n",
      "                        \"container_id\": \"2c2d6603-b329-4254-b68c-2fc135ee819e\"\n",
      "                    }\n",
      "                },\n",
      "                {\n",
      "                    \"type\": \"Token\",\n",
      "                    \"segment\": {\n",
      "                        \"type\": \"Index\",\n",
      "                        \"container_id\": \"9b3b792c-797c-44a2-a340-9f64cd532c67\",\n",
      "                        \"start\": 8,\n",
      "                        \"stop\": 10\n",
      "                    },\n",
      "                    \"source\": \"treebank_tokenizer\",\n",
      "                    \"timestamp\": 1604697979.13138,\n",
      "                    \"value\": \"my\",\n",
      "                    \"id\": \"a7d1eedd-b87f-4315-969d-024f80228895\",\n",
      "                    \"ruler\": {\n",
      "                        \"type\": \"AtomicRuler\",\n",
      "                        \"container_id\": \"a7d1eedd-b87f-4315-969d-024f80228895\"\n",
      "                    }\n",
      "                },\n",
      "                {\n",
      "                    \"type\": \"Token\",\n",
      "                    \"segment\": {\n",
      "                        \"type\": \"Index\",\n",
      "                        \"container_id\": \"9b3b792c-797c-44a2-a340-9f64cd532c67\",\n",
      "                        \"start\": 11,\n",
      "                        \"stop\": 18\n",
      "                    },\n",
      "                    \"source\": \"treebank_tokenizer\",\n",
      "                    \"timestamp\": 1604697979.1314108,\n",
      "                    \"value\": \"brother\",\n",
      "                    \"id\": \"e08897df-91e2-43e6-9f79-3112d930cb9a\",\n",
      "                    \"ruler\": {\n",
      "                        \"type\": \"AtomicRuler\",\n",
      "                        \"container_id\": \"e08897df-91e2-43e6-9f79-3112d930cb9a\"\n",
      "                    }\n",
      "                },\n",
      "                {\n",
      "                    \"type\": \"Token\",\n",
      "                    \"segment\": {\n",
      "                        \"type\": \"Index\",\n",
      "                        \"container_id\": \"9b3b792c-797c-44a2-a340-9f64cd532c67\",\n",
      "                        \"start\": 19,\n",
      "                        \"stop\": 22\n",
      "                    },\n",
      "                    \"source\": \"treebank_tokenizer\",\n",
      "                    \"timestamp\": 1604697979.1314318,\n",
      "                    \"value\": \"Jim\",\n",
      "                    \"id\": \"b4c4381f-73e7-4573-a3c2-ed7730020e0a\",\n",
      "                    \"ruler\": {\n",
      "                        \"type\": \"AtomicRuler\",\n",
      "                        \"container_id\": \"b4c4381f-73e7-4573-a3c2-ed7730020e0a\"\n",
      "                    }\n",
      "                }\n",
      "            ],\n",
      "            \"id\": \"c291eef1-9f44-4bc3-b8cb-c3071081ce54\",\n",
      "            \"ruler\": {\n",
      "                \"type\": \"Index\",\n",
      "                \"container_id\": \"c291eef1-9f44-4bc3-b8cb-c3071081ce54\",\n",
      "                \"start\": 0,\n",
      "                \"stop\": 5\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"PersonAnnotation\",\n",
      "            \"segment\": {\n",
      "                \"type\": \"Index\",\n",
      "                \"container_id\": \"c291eef1-9f44-4bc3-b8cb-c3071081ce54\",\n",
      "                \"start\": 4,\n",
      "                \"stop\": 4\n",
      "            },\n",
      "            \"source\": \"annotator_1\",\n",
      "            \"timestamp\": 1604697979.13238,\n",
      "            \"person\": {\n",
      "                \"id\": \"50767d79-1ac2-422a-a278-56e5daaccbd2\",\n",
      "                \"name\": \"Jim\",\n",
      "                \"age\": 32,\n",
      "                \"gender\": \"MALE\",\n",
      "                \"emotion\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"seq\": null,\n",
      "    \"id\": \"9b3b792c-797c-44a2-a340-9f64cd532c67\",\n",
      "    \"ruler\": {\n",
      "        \"type\": \"Index\",\n",
      "        \"container_id\": \"9b3b792c-797c-44a2-a340-9f64cd532c67\",\n",
      "        \"start\": 0,\n",
      "        \"stop\": 23\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "speaker = piek\n",
    "\n",
    "transcript = scenario_data_path(scenario_id, \"chat1_utterance1.txt\", Modality.TEXT)\n",
    "with open(transcript) as f:\n",
    "    utterance = f.readline()\n",
    "\n",
    "utterance_time = scenario.ruler.get_time_segment(1603139850, 1603149890)\n",
    "text_signal =  TextSignal(None, utterance_time, [transcript], len(utterance))\n",
    "\n",
    "tokens = tokenize(utterance)\n",
    "token_annotations = [Token(token[1], text_signal.ruler.get_offset(*token[0]), \"treebank_tokenizer\", time.time())\n",
    "                     for token in tokens]\n",
    "text_signal.mentions.extend(token_annotations)\n",
    "\n",
    "utterance_annotation = UtteranceAnnotation(None, None, utterance, token_annotations, piek, Emotion.JOY, \"annotator_1\", time.time())\n",
    "text_signal.mentions.append(utterance_annotation)\n",
    "\n",
    "token = tokens[4]\n",
    "jim = Friend(None, token[1], 32, Gender.MALE, None)\n",
    "person_annotation = PersonAnnotation(jim, utterance_annotation.ruler.get_offset(4,4), \"annotator_1\", time.time())\n",
    "text_signal.mentions.append(person_annotation)\n",
    "\n",
    "utt_ruler = utterance_annotation.ruler\n",
    "triple_segments = (utt_ruler.get_offset(2,2), utt_ruler.get_offset(3,3), utt_ruler.get_offset(4,4))\n",
    "triples = (Triple.from_friends(triple_segments, str(speaker.id), \"brother-of\", str(jim.id), \"annotator_1\", time.time()),)\n",
    "\n",
    "print(json.dumps(text_signal, default=serializer, indent=4))\n",
    "append_signal(scenario.signals[Modality.TEXT.name.lower()], text_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the annotation that goes with a family picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"modality\": \"IMAGE\",\n",
      "    \"time\": {\n",
      "        \"type\": \"TemporalRuler\",\n",
      "        \"container_id\": \"test_scenario\",\n",
      "        \"start\": 1603139840,\n",
      "        \"end\": 1603149860\n",
      "    },\n",
      "    \"files\": [\n",
      "        \"data/test-scenes/test_scenario/image/pexels-victoria-borodinova-1648358.jpg\"\n",
      "    ],\n",
      "    \"mentions\": [\n",
      "        {\n",
      "            \"type\": \"PersonAnnotation\",\n",
      "            \"segment\": {\n",
      "                \"type\": \"MultiIndex\",\n",
      "                \"container_id\": \"87505005-be32-40b9-90bd-8d175039be91\",\n",
      "                \"bounds\": [\n",
      "                    [\n",
      "                        450,\n",
      "                        1200\n",
      "                    ],\n",
      "                    [\n",
      "                        1280,\n",
      "                        1900\n",
      "                    ]\n",
      "                ]\n",
      "            },\n",
      "            \"source\": \"face_recognition\",\n",
      "            \"timestamp\": 1604697979.1626801,\n",
      "            \"person\": {\n",
      "                \"id\": \"50767d79-1ac2-422a-a278-56e5daaccbd2\",\n",
      "                \"name\": \"Jim\",\n",
      "                \"age\": 32,\n",
      "                \"gender\": \"MALE\",\n",
      "                \"emotion\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"array\": null,\n",
      "    \"id\": \"87505005-be32-40b9-90bd-8d175039be91\",\n",
      "    \"ruler\": {\n",
      "        \"type\": \"MultiIndex\",\n",
      "        \"container_id\": \"87505005-be32-40b9-90bd-8d175039be91\",\n",
      "        \"bounds\": [\n",
      "            [\n",
      "                0,\n",
      "                3456\n",
      "            ],\n",
      "            [\n",
      "                0,\n",
      "                5184\n",
      "            ]\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "family_img_file = scenario_data_path(scenario_id, \"pexels-victoria-borodinova-1648358.jpg\", Modality.IMAGE)\n",
    "family_img_time = scenario.ruler.get_time_segment(1603139840, 1603149860)\n",
    "\n",
    "family_img_signal = ImageSignal(None, family_img_time, [family_img_file], ((0, 3456), (0, 5184)))\n",
    "jim_bounding_box = family_img_signal.ruler.get_area_bounding_box(450,1280,1200,1900)\n",
    "\n",
    "jim_annotation = PersonAnnotation(jim, jim_bounding_box, \"face_recognition\", time.time())\n",
    "family_img_signal.mentions.append(jim_annotation)\n",
    "\n",
    "print(json.dumps(family_img_signal, default=serializer, indent=4))\n",
    "append_signal(scenario.signals[Modality.IMAGE.name.lower()], family_img_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation of the communication about the picture(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for signal_file in scenario.signals.values():\n",
    "    append_signal(signal_file, None, terminate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Leolani domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from integration.convert import convert, integrate_image_signal, integrate_text_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leolani_context = convert(scenario)\n",
    "# print(json.dumps(leolani_context, default=vars, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(str([(topic, vars(ev)) for topic, ev in integrate_image_signal(speaker_img_signal)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# events, triples = integrate_text_signal(text_signal, leolani_context)\n",
    "# print(str([(topic, vars(ev)) for topic, ev in events]))\n",
    "# print()\n",
    "# print(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json.dumps(leolani_context, default=vars, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
